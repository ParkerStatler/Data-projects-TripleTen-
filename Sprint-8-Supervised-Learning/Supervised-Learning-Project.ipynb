{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customers Leaving Beta Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of customers are leaving the bank, predict how many will leave. Download the customer data and preprocess is to create different models. Improve the models to find which one will best suit the data, then find the total customers predicted to leave the bank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the tenure data is missing, so we'll fill it with the median of those values\n",
    "data.loc[data['Tenure'].isna(),'Tenure'] = data['Tenure'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once we perform OHE, there will be a bunch of surname features making the data difficult to visualize\n",
    "# The surname column isn't relevant to our analysis, so it can be dropped\n",
    "data = data.drop('Surname', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if any of the customers data was duplicated\n",
    "data['CustomerId'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAE3CAYAAAC0Kga7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2WElEQVR4nO3de1zO9/8/8MdVuq4OuiqHSrTkMOQUZSQzI0UxhhFtQs7lUJtDnznbHHKWMNsctmE222xEh2UYmogQzXnYqNCJ0Ol6//7w7f1zuXLpnatd1/K4325uvF/v1/W+nu/reuvR+/U+yQRBEEBERPQcRvougIiIDBuDgoiItGJQEBGRVgwKIiLSikFBRERaMSiIiEgrBgUREWnFoCAiIq0YFEREpBWDgv7T5syZA5lMhrt37+q7FKokf/31F2QyGTZv3qzvUl5ZDAp6KZs3b4ZMJlP7Y2tri7fffhv79u3Td3nlcuXKFYwZMwYNGjSAqakplEolPD09sWrVKjx69KhS3nPbtm1YuXJlpSxb38raJp7+88cff7z0e+zduxdz5sx5+WKpXKrpuwCqGubNmwdnZ2cIgoCMjAxs3rwZvr6+2L17N3r16qXv8p4rOjoa7733HhQKBYYOHYoWLVqgsLAQhw8fxpQpU3Du3Dls2LBB5++7bds2pKamYvLkyTpftqEo3Sae1ahRI0nLcXJywqNHj2BiYiK27d27F1FRUQyLfwmDgnSiZ8+ecHd3F6eDgoJgZ2eH7du3G2xQXLt2Df7+/nBycsL+/ftRp04dcV5wcDAuX76M6OhoPVZouPLz82FhYaG1z7PbREXJZDKYmpq+9HKo4jj0RJXC2toaZmZmqFZN/XeRpUuXomPHjqhZsybMzMzg5uaGnTt3arxeJpMhJCQEu3btQosWLaBQKNC8eXPExMS88L2vX7+ORo0aoUWLFsjIyHhuv4iICDx48ABffvmlWkiUatSoESZNmgRA+zi5TCZT+832/v37mDx5MurXrw+FQgFbW1t0794dJ0+eBAB06dIF0dHRuH79ujgcU79+ffH1mZmZYtCampqidevW2LJli9p7ltazdOlSREVFoUGDBjA3N4e3tzdu3rwJQRAwf/581KtXD2ZmZujTpw+ysrI0at+3bx/efPNNWFhYwNLSEn5+fjh37pxan2HDhqF69eq4cuUKfH19YWlpiYCAgOd+ruU1e/ZsGBkZISEhQa199OjRkMvlOH36tNq6ln72w4YNQ1RUFACoDWmV+vbbb+Hm5gZLS0solUq0bNkSq1ateul6X2XcoyCdyM3Nxd27dyEIAjIzMxEZGYkHDx7g/fffV+u3atUqvPPOOwgICEBhYSG+/fZbvPfee9izZw/8/PzU+h4+fBg//vgjxo8fD0tLS6xevRr9+/fHjRs3ULNmzTLruHLlCrp27YoaNWogPj4etWrVem7Nu3fvRoMGDdCxY8eX/wCeMnbsWOzcuRMhISFwcXHBvXv3cPjwYaSlpaFt27b4+OOPkZubi7///hsrVqwAAFSvXh0A8OjRI3Tp0gWXL19GSEgInJ2d8f3332PYsGHIyckRg6vU1q1bUVhYiAkTJiArKwsREREYOHAgunbtigMHDmDatGm4fPkyIiMj8dFHH2Hjxo3ia7/++msEBgbCx8cHixcvxsOHD7Fu3Tp06tQJp06dUguv4uJi+Pj4oFOnTli6dCnMzc1f+DmUbhNPk8lk4nc3Y8YM7N69G0FBQTh79iwsLS0RGxuLzz//HPPnz0fr1q3LXO6YMWNw69YtxMfH4+uvv1abFx8fj8GDB6Nbt25YvHgxACAtLQ1HjhzR+OxIAoHoJWzatEkAoPFHoVAImzdv1uj/8OFDtenCwkKhRYsWQteuXdXaAQhyuVy4fPmy2Hb69GkBgBAZGSm2zZ49WwAg3LlzR0hLSxMcHByEdu3aCVlZWVrrzs3NFQAIffr0Kdd6Xrt2TQAgbNq0SWMeAGH27NnitJWVlRAcHKx1eX5+foKTk5NG+8qVKwUAwjfffCO2FRYWCh4eHkL16tWFvLw8tXpq164t5OTkiH3Dw8MFAELr1q2FoqIisX3w4MGCXC4XHj9+LAiCINy/f1+wtrYWRo0apfb+6enpgpWVlVp7YGCgAECYPn261nUq9bxtonS7eNrZs2cFuVwujBw5UsjOzhbq1q0ruLu7q9Ve1mcfHBwslPXja9KkSYJSqRSKi4vLVSuVD/coSCeioqLw+uuvAwAyMjLwzTffYOTIkbC0tES/fv3EfmZmZuK/s7OzUVJSgjfffBPbt2/XWKaXlxcaNmwoTrdq1QpKpRJXr17V6JuamopBgwahUaNG2LdvH5RKpdZ68/LyAACWlpbSVrQcrK2tcezYMdy6dQsODg6SXrt3717Y29tj8ODBYpuJiQkmTpyIwYMH4+DBg2rHfN577z1YWVmJ0+3btwcAvP/++2rDfu3bt8f27dvxzz//oEGDBoiPj0dOTg4GDx6s9lu/sbEx2rdvj99++02jtnHjxklal6e3iaeX/7QWLVpg7ty5CA8Px5kzZ3D37l3ExcVpDFmWl7W1NfLz8xEfH48ePXpUaBmkiUFBOvHGG2+oHbgcPHgw2rRpg5CQEPTq1QtyuRwAsGfPHnzyySdISUlBQUGB2P/pMeZSr732mkabjY0NsrOzNdp79+4NOzs7xMbGisM42pQGyf3791+8chJFREQgMDAQjo6OcHNzg6+vL4YOHYoGDRq88LXXr19H48aNYWSkfviwWbNm4vynPfsZlYaGo6Njme2ln92lS5cAAF27di2zjmeDtlq1aqhXr94L63/as9vE80yZMgXffvstkpKSsGDBAri4uEh6n6eNHz8e3333HXr27Im6devC29sbAwcOZGi8JB7MpkphZGSEt99+G7dv3xZ/KP3+++945513YGpqirVr12Lv3r2Ij4/HkCFDIJTxRN5nf/ssVVbf/v3748qVK9i6dWu56lMqlXBwcEBqamq5+pcVZABQUlKi0TZw4EBcvXoVkZGRcHBwwJIlS9C8efNKua7keZ/Riz47lUoF4Mlxivj4eI0/P//8s9rrFAqFRnjpytWrV8Vt5OzZsy+1LFtbW6SkpOCXX37BO++8g99++w09e/ZEYGCgLkp9ZXGPgipNcXExAODBgwcAgB9++AGmpqaIjY2FQqEQ+23atOml32vJkiWoVq2aeOB7yJAhL3xNr169sGHDBiQmJsLDw0NrXxsbGwBATk6OWvuzv+GXqlOnDsaPH4/x48cjMzMTbdu2xaeffoqePXsCeH7wODk54cyZM1CpVGo/mP/8809xvi6UDunZ2trCy8tLJ8usCJVKhWHDhkGpVGLy5MlYsGABBgwYoDZcWZbnfX4AIJfL0bt3b/Tu3RsqlQrjx4/HZ599hpkzZ0q+hoOe4B4FVYqioiLExcVBLpeLwybGxsaQyWRqv4X/9ddf2LVr10u/n0wmw4YNGzBgwAAEBgbil19+eeFrpk6dCgsLC4wcObLM02ivXLkinlapVCpRq1YtHDp0SK3P2rVr1aZLSkqQm5ur1mZrawsHBwe1oTYLCwuNfgDg6+uL9PR07NixQ2wrLi5GZGQkqlevjrfeeuuF61UePj4+UCqVWLBgAYqKijTm37lzRyfv8yLLly/H0aNHsWHDBsyfPx8dO3bEuHHjXnhLltJrOJ4N7nv37qlNGxkZoVWrVgCg9vmTNNyjIJ3Yt2+f+FtvZmYmtm3bhkuXLmH69OnieLefnx+WL1+OHj16YMiQIcjMzERUVBQaNWqEM2fOvHQNRkZG+Oabb9C3b18MHDgQe/fufe4YPPDkt+pt27Zh0KBBaNasmdqV2UePHhVPSy01cuRILFq0CCNHjoS7uzsOHTqEixcvqi3z/v37qFevHgYMGIDWrVujevXq+PXXX3H8+HEsW7ZM7Ofm5oYdO3YgLCwM7dq1Q/Xq1dG7d2+MHj0an332GYYNG4bk5GTUr18fO3fuxJEjR7By5UqdHXxXKpVYt24dPvjgA7Rt2xb+/v6oXbs2bty4gejoaHh6emLNmjUv9R5PbxNP69ixIxo0aIC0tDTMnDkTw4YNQ+/evQE8uf2Hq6ureKzhedzc3AAAEydOhI+PD4yNjeHv74+RI0ciKysLXbt2Rb169XD9+nVERkbC1dVV/IWFKkDPZ13Rf1xZp0KampoKrq6uwrp16wSVSqXW/8svvxQaN24sKBQKoWnTpsKmTZvEU1yfBqDMU0ydnJyEwMBAcfrp02NLPXz4UHjrrbeE6tWrC3/88ccL1+HixYvCqFGjhPr16wtyuVywtLQUPD09hcjISPF00tLlBgUFCVZWVoKlpaUwcOBAITMzU+302IKCAmHKlClC69atBUtLS8HCwkJo3bq1sHbtWrX3fPDggTBkyBDB2tpaAKB2qmxGRoYwfPhwoVatWoJcLhdatmypcVpu6SmjS5YsUWv/7bffBADC999/r9Ze+j0dP35co7+Pj49gZWUlmJqaCg0bNhSGDRsmnDhxQuwTGBgoWFhYvPBzfPa9nvdn06ZNQnFxsdCuXTuhXr16aqf3CoIgrFq1SgAg7NixQ21dn/4MiouLhQkTJgi1a9cWZDKZuP3s3LlT8Pb2FmxtbQW5XC689tprwpgxY4Tbt2+Xu37SJBOEMo4MEhER/R8eoyAiIq0YFEREpBWDgoiItGJQEBGRVgwKIiLSikFBRERa8YK7clCpVLh16xYsLS213jqAiOi/QhAE3L9/Hw4ODi+8jxeDohxu3bqlcTdOIqKq4ObNmy+8MzCDohxKb5tw8+bNFz7ngP6/0vs9eXt7w8TERN/lUBXGbU26vLw8ODo6luu2MAyKcigdblIqlQwKCYqKimBubg6lUsn/vFSpuK1VXHmG03kwm4iItGJQEBGRVgwKIiLSSq9BUVJSgpkzZ8LZ2RlmZmZo2LAh5s+fr/aoS0EQMGvWLNSpUwdmZmbw8vISH5tYKisrCwEBAVAqlbC2tkZQUJD4VLVSZ86cwZtvvglTU1M4OjoiIiLiX1lHIqL/Or0GxeLFi7Fu3TqsWbMGaWlpWLx4MSIiIhAZGSn2iYiIwOrVq7F+/XocO3YMFhYW8PHxwePHj8U+AQEBOHfuHOLj47Fnzx4cOnQIo0ePFufn5eXB29sbTk5OSE5OxpIlSzBnzhxs2LDhX11fIqL/JH0+DMPPz08YMWKEWlu/fv2EgIAAQRAEQaVSCfb29moPZ8nJyREUCoWwfft2QRAE4fz58xoPZNm3b58gk8mEf/75RxAEQVi7dq1gY2MjFBQUiH2mTZsmNGnSpFx15ubmCgCE3Nzciq3oK6qwsFDYtWuXUFhYqO9SqIrjtiadlJ9rej09tmPHjtiwYQMuXryI119/HadPn8bhw4exfPlyAMC1a9eQnp6u9vB3KysrtG/fHomJifD390diYiKsra3h7u4u9vHy8oKRkRGOHTuGd999F4mJiejcuTPkcrnYx8fHB4sXL0Z2djZsbGzU6iooKFB7vm5eXh6AJ6fglfV8YSpb6WfFz4wqG7c16aR8VnoNiunTpyMvLw9NmzaFsbExSkpK8OmnnyIgIAAAkJ6eDgCws7NTe52dnZ04Lz09Hba2tmrzq1Wrhho1aqj1cXZ21lhG6bxng2LhwoWYO3euRr1xcXEwNzev6Oq+suLj4/VdAr0iuK2V38OHD8vdV69B8d1332Hr1q3Ytm0bmjdvjpSUFEyePBkODg4IDAzUW13h4eEICwsTp0uvYPT29jbIC+5azInVdwllUhgJmO+uwswTRihQGd49slLn+Oi7BNKRoqIixMfHo3v37rzgrpxKR0rKQ69BMWXKFEyfPh3+/v4AgJYtW+L69etYuHAhAgMDYW9vDwDIyMhAnTp1xNdlZGTA1dUVAGBvb4/MzEy15RYXFyMrK0t8vb29PTIyMtT6lE6X9nmaQqGAQqHQaDcxMTHIjbCgxPB+CD+tQCUzyBoN8bukl2Oo/0cNkZTPSa9nPT18+FDjroXGxsZQqVQAAGdnZ9jb2yMhIUGcn5eXh2PHjsHDwwMA4OHhgZycHCQnJ4t99u/fD5VKhfbt24t9Dh06pDYmFx8fjyZNmmgMOxERkTq9BkXv3r3x6aefIjo6Gn/99Rd++uknLF++HO+++y6AJ/cgmTx5Mj755BP88ssvOHv2LIYOHQoHBwf07dsXANCsWTP06NEDo0aNQlJSEo4cOYKQkBD4+/vDwcEBADBkyBDI5XIEBQXh3Llz2LFjB1atWqU2vERERGXT69BTZGQkZs6cifHjxyMzMxMODg4YM2YMZs2aJfaZOnUq8vPzMXr0aOTk5KBTp06IiYmBqamp2Gfr1q0ICQlBt27dYGRkhP79+2P16tXifCsrK8TFxSE4OBhubm6oVasWZs2apXatBRERlU0mCE9dBk1lysvLg5WVFXJzcw3yYHb96dH6LqFMCmMBEW+UYGqSsUEeo/hrkZ++SyAdKSoqwt69e+Hr68tjFOUk5eca7/VERERaMSiIiEgrBgUREWnFoCAiIq0YFEREpBWDgoiItGJQEBGRVgwKIiLSikFBRERaMSiIiEgrBgUREWnFoCAiIq0YFEREpBWDgoiItGJQEBGRVgwKIiLSikFBRERaMSiIiEgrBgUREWnFoCAiIq0YFEREpBWDgoiItGJQEBGRVgwKIiLSSnJQxMTE4PDhw+J0VFQUXF1dMWTIEGRnZ+u0OCIi0j/JQTFlyhTk5eUBAM6ePYsPP/wQvr6+uHbtGsLCwnReIBER6Vc1qS+4du0aXFxcAAA//PADevXqhQULFuDkyZPw9fXVeYFERKRfkvco5HI5Hj58CAD49ddf4e3tDQCoUaOGuKdBRERVh+Q9Ck9PT4SFhcHT0xNJSUnYsWMHAODixYuoV6+ezgskIiL9krxHERUVBRMTE+zcuRPr1q1D3bp1AQD79u1Djx49dF4gERHpl6Q9iuLiYhw4cACff/457O3t1eatWLFCp4UREZFhkLRHUa1aNYwdOxYFBQWVVQ8RERkYyUNPb7zxBk6dOlUZtRARkQGSfDB7/Pjx+PDDD/H333/Dzc0NFhYWavNbtWqls+KIiEj/JAeFv78/AGDixIlim0wmgyAIkMlkKCkp0V11RESkdxW64I6IiF4dkoPCycmpMuogIiIDVaG7x3799dfw9PSEg4MDrl+/DgBYuXIlfv75Z50WR0RE+ic5KNatW4ewsDD4+voiJydHPCZhbW2NlStX6ro+IiLSM8lBERkZic8//xwff/wxjI2NxXZ3d3ecPXtWp8UREZH+SQ6Ka9euoU2bNhrtCoUC+fn5OimKiIgMh+SgcHZ2RkpKikZ7TEwMmjVrpouaiIjIgEg+6yksLAzBwcF4/PgxBEFAUlIStm/fjoULF+KLL76ojBqJiEiPJAfFyJEjYWZmhhkzZuDhw4cYMmQIHBwcsGrVKvFiPCIiqjoqdHpsQEAALl26hAcPHiA9PR1///03goKCKlTAP//8g/fffx81a9aEmZkZWrZsiRMnTojzBUHArFmzUKdOHZiZmcHLywuXLl1SW0ZWVhYCAgKgVCphbW2NoKAgPHjwQK3PmTNn8Oabb8LU1BSOjo6IiIioUL1ERK+aCgVFKXNzc9ja2lb49dnZ2fD09ISJiQn27duH8+fPY9myZbCxsRH7REREYPXq1Vi/fj2OHTsGCwsL+Pj44PHjx2KfgIAAnDt3DvHx8dizZw8OHTqE0aNHi/Pz8vLg7e0NJycnJCcnY8mSJZgzZw42bNhQ4dqJiF4Vkoee7t27h1mzZuG3335DZmYmVCqV2vysrKxyL2vx4sVwdHTEpk2bxDZnZ2fx34IgYOXKlZgxYwb69OkDAPjqq69gZ2eHXbt2wd/fH2lpaYiJicHx48fh7u4O4MkpvL6+vli6dCkcHBywdetWFBYWYuPGjZDL5WjevDlSUlKwfPlytUAhIiJNkoPigw8+wOXLlxEUFAQ7OzvIZLIKv/kvv/wCHx8fvPfeezh48CDq1q2L8ePHY9SoUQCenIqbnp4OLy8v8TVWVlZo3749EhMT4e/vj8TERFhbW4shAQBeXl4wMjLCsWPH8O677yIxMRGdO3eGXC4X+/j4+GDx4sXIzs5W24MBgIKCArVnbpQ+C7yoqAhFRUUVXt/KojAW9F1CmRRGgtrfhsYQv0uqmNLvkt9p+Un5rCQHxe+//47Dhw+jdevWUl+q4erVq+KV3v/73/9w/PhxTJw4EXK5HIGBgUhPTwcA2NnZqb3Ozs5OnJeenq4x/FWtWjXUqFFDrc/TeypPLzM9PV0jKBYuXIi5c+dq1BsXFwdzc/OXWOPKEfGGvivQbr676sWd9GDv3r36LoF0LD4+Xt8l/Gc8fPiw3H0lB0XTpk3x6NEjqS8rk0qlgru7OxYsWAAAaNOmDVJTU7F+/XoEBgbq5D0qIjw8HGFhYeJ0Xl4eHB0d4e3tDaVSqbe6nqfFnFh9l1AmhZGA+e4qzDxhhAJVxfc8K0vqHB99l0A6UlRUhPj4eHTv3h0mJib6Luc/oXSkpDwkB8XatWsxffp0zJo1Cy1atND4UqT8IK1Tpw5cXFzU2po1a4YffvgBAMTncmdkZKBOnTpin4yMDLi6uop9MjMz1ZZRXFyMrKws8fX29vbIyMhQ61M6/eyzv4EnV5krFAqNdhMTE4PcCAtKDO+H8NMKVDKDrNEQv0t6OYb6f9QQSfmcJJ/1ZG1tjby8PHTt2hW2trawsbGBjY0NrK2tNYZwXsTT0xMXLlxQa7t48aJ4K3NnZ2fY29sjISFBnJ+Xl4djx47Bw8MDAODh4YGcnBwkJyeLffbv3w+VSoX27duLfQ4dOqQ2JhcfH48mTZpIrpmI6FUjeY8iICAAJiYm2LZt20sfzA4NDUXHjh2xYMECDBw4EElJSdiwYYN42qpMJsPkyZPxySefoHHjxnB2dsbMmTPh4OCAvn37AniyB9KjRw+MGjUK69evR1FREUJCQuDv7w8HBwcAwJAhQzB37lwEBQVh2rRpSE1NxapVq7BixYoK105E9KqQHBSpqak4deoUmjRp8tJv3q5dO/z0008IDw/HvHnz4OzsjJUrVyIgIEDsM3XqVOTn52P06NHIyclBp06dEBMTA1NTU7HP1q1bERISgm7dusHIyAj9+/fH6tWrxflWVlaIi4tDcHAw3NzcUKtWLcyaNYunxhIRlYPkoHB3d8fNmzd1EhQA0KtXL/Tq1eu582UyGebNm4d58+Y9t0+NGjWwbds2re/TqlUr/P777xWuk4joVSU5KCZMmIBJkyZhypQpaNmypcYBkVatWumsOCIi0j/JQTFo0CAAwIgRI8Q2mUwGQRAgk8nEJ94REVHVIDkorl27Vhl1EBGRgZIcFKWnrhIR0atBclAAwJUrV7By5UqkpaUBAFxcXDBp0iQ0bNhQp8UREZH+Sb7gLjY2Fi4uLkhKSkKrVq3QqlUrHDt2DM2bN+d9VoiIqiDJexTTp09HaGgoFi1apNE+bdo0dO/eXWfFERGR/kneo0hLSyvzaXYjRozA+fPndVIUEREZDslBUbt2baSkpGi0p6SkvNTT7oiIyDBJHnoaNWoURo8ejatXr6Jjx44AgCNHjmDx4sVqt+YmIqKqQXJQzJw5E5aWlli2bBnCw8MBAA4ODpgzZw4mTpyo8wKJiEi/JAeFTCZDaGgoQkNDcf/+fQCApaWlzgsjIiLDIPkYRdeuXZGTkwPgSUCUhkTpMyqIiKhqkRwUBw4cQGFhoUb748ePeXdWIqIqqNxDT2fOnBH/ff78eaSnp4vTJSUliImJQd26dXVbHRER6V25g8LV1RUymQwymazMISYzMzNERkbqtDgiItK/cgfFtWvXIAgCGjRogKSkJNSuXVucJ5fLYWtrC2Nj40opkoiI9KfcQVF611iVSlVpxRARkeGRfDB7y5YtiI6OFqenTp0Ka2trdOzYEdevX9dpcUREpH+Sg2LBggUwMzMDACQmJmLNmjWIiIhArVq1EBoaqvMCiYhIvyRfcHfz5k00atQIALBr1y4MGDAAo0ePhqenJ7p06aLr+oiISM8k71FUr14d9+7dAwDExcWJtxU3NTXFo0ePdFsdERHpneQ9iu7du2PkyJFo06YNLl68CF9fXwDAuXPnUL9+fV3XR0REeiZ5jyIqKgoeHh64c+cOfvjhB9SsWRMAkJycjMGDB+u8QCIi0i/JexTW1tZYs2aNRvvcuXN1UhARERkWyUFx6NAhrfM7d+5c4WKIiMjwSA6Kss5skslk4r9LSkpeqiAiIjIsko9RZGdnq/3JzMxETEwM2rVrh7i4uMqokYiI9EjyHoWVlZVGW/fu3SGXyxEWFobk5GSdFEZERIZB8h7F89jZ2eHChQu6WhwRERkIyXsUTz+XAgAEQcDt27exaNEiuLq66qouIiIyEJKDovS5FIIgqLV36NABGzdu1FlhRERkGCQHxbVr19SmjYyMULt2bZiamuqsKCIiMhySg6L0uRRERPRqKPfB7P3798PFxQV5eXka83Jzc9G8eXP8/vvvOi2OiIj0r9xBsXLlSowaNQpKpVJjnpWVFcaMGYPly5frtDgiItK/cgfF6dOn0aNHj+fO9/b25jUURERVULmDIiMjAyYmJs+dX61aNdy5c0cnRRERkeEod1DUrVsXqampz51/5swZ1KlTRydFERGR4Sh3UPj6+mLmzJl4/PixxrxHjx5h9uzZ6NWrl06LIyIi/Sv36bEzZszAjz/+iNdffx0hISFo0qQJAODPP/9EVFQUSkpK8PHHH1daoUREpB/lDgo7OzscPXoU48aNQ3h4uHhltkwmg4+PD6KiomBnZ1dphRIRkX5IuuDOyckJe/fuRXZ2Ni5fvgxBENC4cWPY2NhUVn1ERKRnkq/MBgAbGxu0a9dO17UQEZEB0tltxl/WokWLIJPJMHnyZLHt8ePHCA4ORs2aNVG9enX0798fGRkZaq+7ceMG/Pz8YG5uDltbW0yZMgXFxcVqfQ4cOIC2bdtCoVCgUaNG2Lx587+wRkREVYNBBMXx48fx2WefoVWrVmrtoaGh2L17N77//nscPHgQt27dQr9+/cT5JSUl8PPzQ2FhIY4ePYotW7Zg8+bNmDVrltjn2rVr8PPzw9tvv42UlBRMnjwZI0eORGxs7L+2fkRE/2V6D4oHDx4gICAAn3/+udqxjtzcXHz55ZdYvnw5unbtCjc3N2zatAlHjx7FH3/8AQCIi4vD+fPn8c0338DV1RU9e/bE/PnzERUVhcLCQgDA+vXr4ezsjGXLlqFZs2YICQnBgAEDsGLFCr2sLxHRf025jlG0bdsWCQkJsLGxwbx58/DRRx/B3NxcJwUEBwfDz88PXl5e+OSTT8T25ORkFBUVwcvLS2xr2rQpXnvtNSQmJqJDhw5ITExEy5Yt1c628vHxwbhx43Du3Dm0adMGiYmJasso7fP0ENezCgoKUFBQIE6X3gixqKgIRUVFL7vKOqcwFl7cSQ8URoLa34bGEL9LqpjS75LfaflJ+azKFRRpaWnIz8+HjY0N5s6di7Fjx+okKL799lucPHkSx48f15iXnp4OuVwOa2trtXY7Ozukp6eLfZ49Jbd0+kV98vLy8OjRI5iZmWm898KFCzF37lyN9ri4OJ0FpC5FvKHvCrSb767Sdwll2rt3r75LIB2Lj4/Xdwn/GQ8fPix333IFhaurK4YPH45OnTpBEAQsXboU1atXL7Pv08cHtLl58yYmTZqE+Ph4g3voUXh4OMLCwsTpvLw8ODo6wtvbu8y75+pbizmGebxFYSRgvrsKM08YoUAl03c5GlLn+Oi7BNKRoqIixMfHo3v37lrvSUf/X1mPjHiecgXF5s2bMXv2bOzZswcymQz79u1DtWqaL5XJZOUOiuTkZGRmZqJt27ZiW0lJCQ4dOoQ1a9YgNjYWhYWFyMnJUduryMjIgL29PQDA3t4eSUlJasstPSvq6T7PnimVkZEBpVJZ5t4EACgUCigUCo12ExMTg9wIC0oM74fw0wpUMoOs0RC/S3o5hvp/1BBJ+ZzKFRRNmjTBt99+C+DJo08TEhJga2tbser+T7du3XD27Fm1tuHDh6Np06aYNm0aHB0dYWJigoSEBPTv3x8AcOHCBdy4cQMeHh4AAA8PD3z66afIzMwU64mPj4dSqYSLi4vY59khhvj4eHEZRESkneQL7lQq3Yw3W1paokWLFmptFhYWqFmzptgeFBSEsLAw1KhRA0qlEhMmTICHhwc6dOgA4MkzMFxcXPDBBx8gIiIC6enpmDFjBoKDg8U9grFjx2LNmjWYOnUqRowYgf379+O7775DdHS0TtaDiKiqq9CV2VeuXMHKlSuRlpYGAHBxccGkSZPQsGFDnRa3YsUKGBkZoX///igoKICPjw/Wrl0rzjc2NsaePXswbtw4eHh4wMLCAoGBgZg3b57Yx9nZGdHR0QgNDcWqVatQr149fPHFF/Dx4fg0EVF5SA6K2NhYvPPOO3B1dYWnpycA4MiRI2jevDl2796N7t27V7iYAwcOqE2bmpoiKioKUVFRz31N6f2ntOnSpQtOnTpV4bqIiF5lkoNi+vTpCA0NxaJFizTap02b9lJBQUREhkfyldlpaWkICgrSaB8xYgTOnz+vk6KIiMhwSA6K2rVrIyUlRaM9JSXlpc+EIiIiwyN56GnUqFEYPXo0rl69io4dOwJ4coxi8eLFahepERFR1SA5KGbOnAlLS0ssW7YM4eHhAAAHBwfMmTMHEydO1HmBRESkX5KDQiaTITQ0FKGhobh//z6AJ9dEEBFR1VSh6yhKMSCIiKo+vT+PgoiIDBuDgoiItGJQEBGRVpKCoqioCN26dcOlS5cqqx4iIjIwkoLCxMQEZ86cqaxaiIjIAEkeenr//ffx5ZdfVkYtRERkgCSfHltcXIyNGzfi119/hZubGywsLNTmL1++XGfFERGR/kkOitTUVPHxpRcvXlSbJ5MZ3uMuiYjo5UgOit9++60y6iAiIgNV4dNjL1++jNjYWDx69AgAIAiCzooiIiLDITko7t27h27duuH111+Hr68vbt++DeDJ860//PBDnRdIRET6JTkoQkNDYWJighs3bsDc3FxsHzRoEGJiYnRaHBER6Z/kYxRxcXGIjY1FvXr11NobN26M69ev66wwIiIyDJL3KPLz89X2JEplZWVBoVDopCgiIjIckoPizTffxFdffSVOy2QyqFQqRERE4O2339ZpcUREpH+Sh54iIiLQrVs3nDhxAoWFhZg6dSrOnTuHrKwsHDlypDJqJCIiPZK8R9GiRQtcvHgRnTp1Qp8+fZCfn49+/frh1KlTaNiwYWXUSEREelShJ9xZWVnh448/1nUtRERkgCoUFNnZ2fjyyy+RlpYGAHBxccHw4cNRo0YNnRZHRET6J3no6dChQ6hfvz5Wr16N7OxsZGdnY/Xq1XB2dsahQ4cqo0YiItIjyXsUwcHBGDRoENatWwdjY2MAQElJCcaPH4/g4GCcPXtW50USEZH+SN6juHz5Mj788EMxJADA2NgYYWFhuHz5sk6LIyIi/ZMcFG3bthWPTTwtLS0NrVu31klRRERkOMo19PT0408nTpyISZMm4fLly+jQoQMA4I8//kBUVBQWLVpUOVUSEZHelCsoXF1dIZPJ1G4lPnXqVI1+Q4YMwaBBg3RXHRER6V25guLatWuVXQcRERmocgWFk5NTZddBREQGqkIX3N26dQuHDx9GZmYmVCqV2ryJEyfqpDAiIjIMkoNi8+bNGDNmDORyOWrWrAmZTCbOk8lkDAoioipGclDMnDkTs2bNQnh4OIyMKvzIbSIi+o+Q/JP+4cOH8Pf3Z0gQEb0iJP+0DwoKwvfff18ZtRARkQGSPPS0cOFC9OrVCzExMWjZsiVMTEzU5i9fvlxnxRERkf5VKChiY2PRpEkTANA4mE1ERFWL5KBYtmwZNm7ciGHDhlVCOUREZGgkH6NQKBTw9PSsjFqIiMgASQ6KSZMmITIysjJqISIiAyR56CkpKQn79+/Hnj170Lx5c42D2T/++KPOiiMiIv2TvEdhbW2Nfv364a233kKtWrVgZWWl9keKhQsXol27drC0tIStrS369u2LCxcuqPV5/PgxgoODUbNmTVSvXh39+/dHRkaGWp8bN27Az88P5ubmsLW1xZQpU1BcXKzW58CBA2jbti0UCgUaNWqEzZs3S111IqJXkuQ9ik2bNunszQ8ePIjg4GC0a9cOxcXF+N///gdvb2+cP38eFhYWAIDQ0FBER0fj+++/h5WVFUJCQtCvXz8cOXIEwJPHsPr5+cHe3h5Hjx7F7du3MXToUJiYmGDBggUAntz91s/PD2PHjsXWrVuRkJCAkSNHok6dOvDx8dHZ+hARVUUy4emHTOjZnTt3YGtri4MHD6Jz587Izc1F7dq1sW3bNgwYMAAA8Oeff6JZs2ZITExEhw4dsG/fPvTq1Qu3bt2CnZ0dAGD9+vWYNm0a7ty5A7lcjmnTpiE6Ohqpqanie/n7+yMnJwcxMTEvrCsvLw9WVlbIzc2FUqmsnJV/CfWnR+u7hDIpjAVEvFGCqUnGKCgxvFOn/1rkp+8SSEeKioqwd+9e+Pr6agyHU9mk/FyTvEfh7Oys9XqJq1evSl2kKDc3FwBQo0YNAEBycjKKiorg5eUl9mnatClee+01MSgSExPRsmVLMSQAwMfHB+PGjcO5c+fQpk0bJCYmqi2jtM/kyZPLrKOgoAAFBQXidF5eHoAnG2NRUVGF16+yKIwNJuvVKIwEtb8NjSF+l4auxZxYfZdQJoWRgPnugNu8GBSoDO+XktQ5hjdyIWX7lxwUz/5wLSoqwqlTpxATE4MpU6ZIXZxIpVJh8uTJ8PT0RIsWLQAA6enpkMvlsLa2VutrZ2eH9PR0sc/TIVE6v3Setj55eXl49OgRzMzM1OYtXLgQc+fO1agxLi4O5ubmFV7HyhLxhr4r0G6+u+rFnfRg7969+i7hP4fbWsUY4rb28OHDcveVHBSTJk0qsz0qKgonTpyQujhRcHAwUlNTcfjw4QovQ1fCw8MRFhYmTufl5cHR0RHe3t4GOfRk2L/lqTDzhBF/y6siuK1VjCFua6UjJeVRoQcXlaVnz54IDw+v0MHukJAQ7NmzB4cOHUK9evXEdnt7exQWFiInJ0dtryIjIwP29vZin6SkJLXllZ4V9XSfZ8+UysjIgFKp1NibAJ5cVKhQKDTaTUxMDHL80xDH/59WoJIZZI2G+F0aOkP8Hp/Gba38pNSks3uF79y5Uzy2UF6CICAkJAQ//fQT9u/fD2dnZ7X5bm5uMDExQUJCgth24cIF3LhxAx4eHgAADw8PnD17FpmZmWKf+Ph4KJVKuLi4iH2eXkZpn9JlEBHR80neo2jTpo3awWxBEJCeno47d+5g7dq1kpYVHByMbdu24eeff4alpaV4TMHKygpmZmawsrJCUFAQwsLCUKNGDSiVSkyYMAEeHh7o0KEDAMDb2xsuLi744IMPEBERgfT0dMyYMQPBwcHiXsHYsWOxZs0aTJ06FSNGjMD+/fvx3XffITraMM8WIiIyJJKDom/fvmrTRkZGqF27Nrp06YKmTZtKWta6desAAF26dFFr37Rpk3jTwRUrVsDIyAj9+/dHQUEBfHx81ALJ2NgYe/bswbhx4+Dh4QELCwsEBgZi3rx5Yh9nZ2dER0cjNDQUq1atQr169fDFF1/wGgoionKQHBSzZ8/W2ZuX5xIOU1NTREVFISoq6rl9nJycXnhWQZcuXXDq1CnJNRIRver4PFMiItKq3HsURkZGL3wwkUwm07jHEhER/beVOyh++umn585LTEzE6tWroVIZ5sUuRERUceUOij59+mi0XbhwAdOnT8fu3bsREBCgdgCZiIiqhgodo7h16xZGjRqFli1bori4GCkpKdiyZQucnJx0XR8REemZpKDIzc3FtGnT0KhRI5w7dw4JCQnYvXu3eG8mIiKqeso99BQREYHFixfD3t4e27dvL3MoioiIqp5yB8X06dNhZmaGRo0aYcuWLdiyZUuZ/fgoVCKiqqXcQTF06NAXnh5LRERVT7mDgs+YJiJ6NfHKbCIi0opBQUREWjEoiIhIKwYFERFpxaAgIiKtGBRERKQVg4KIiLRiUBARkVYMCiIi0opBQUREWjEoiIhIKwYFERFpxaAgIiKtGBRERKQVg4KIiLRiUBARkVYMCiIi0opBQUREWjEoiIhIKwYFERFpxaAgIiKtGBRERKQVg4KIiLRiUBARkVYMCiIi0opBQUREWjEoiIhIKwYFERFpxaAgIiKtGBRERKQVg4KIiLRiUBARkVYMCiIi0opBQUREWr1SQREVFYX69evD1NQU7du3R1JSkr5LIiIyeK9MUOzYsQNhYWGYPXs2Tp48idatW8PHxweZmZn6Lo2IyKC9MkGxfPlyjBo1CsOHD4eLiwvWr18Pc3NzbNy4Ud+lEREZtGr6LuDfUFhYiOTkZISHh4ttRkZG8PLyQmJiokb/goICFBQUiNO5ubkAgKysLBQVFVV+wRJVK87XdwllqqYS8PChCtWKjFCikum7HA337t3Tdwn/OdzWKsYQt7X79+8DAARBeGHfVyIo7t69i5KSEtjZ2am129nZ4c8//9Tov3DhQsydO1ej3dnZudJqrKqG6LsALWot03cFpEvc1irm/v37sLKy0trnlQgKqcLDwxEWFiZOq1QqZGVloWbNmpDJDO+3FUOVl5cHR0dH3Lx5E0qlUt/lUBXGbU06QRBw//59ODg4vLDvKxEUtWrVgrGxMTIyMtTaMzIyYG9vr9FfoVBAoVCotVlbW1dmiVWaUqnkf176V3Bbk+ZFexKlXomD2XK5HG5ubkhISBDbVCoVEhIS4OHhocfKiIgM3yuxRwEAYWFhCAwMhLu7O9544w2sXLkS+fn5GD58uL5LIyIyaK9MUAwaNAh37tzBrFmzkJ6eDldXV8TExGgc4CbdUSgUmD17tsYwHpGucVurXDKhPOdGERHRK+uVOEZBREQVx6AgIiKtGBRERKQVg4KIiLRiUBARkVavzOmxVPnu3r2LjRs3IjExEenp6QAAe3t7dOzYEcOGDUPt2rX1XCERVQT3KEgnjh8/jtdffx2rV6+GlZUVOnfujM6dO8PKygqrV69G06ZNceLECX2XSa+AmzdvYsSIEfouo0rhdRSkEx06dEDr1q2xfv16jRsnCoKAsWPH4syZM2Xe1p1Il06fPo22bduipKRE36VUGRx6Ip04ffo0Nm/eXObddWUyGUJDQ9GmTRs9VEZVzS+//KJ1/tWrV/+lSl4dDArSCXt7eyQlJaFp06Zlzk9KSuLtUkgn+vbtC5lMpvWBO3wcgG4xKEgnPvroI4wePRrJycno1q2bGAoZGRlISEjA559/jqVLl+q5SqoK6tSpg7Vr16JPnz5lzk9JSYGbm9u/XFXVxqAgnQgODkatWrWwYsUKrF27VhwfNjY2hpubGzZv3oyBAwfquUqqCtzc3JCcnPzcoHjR3gZJx4PZpHNFRUW4e/cugCcPjTIxMdFzRVSV/P7778jPz0ePHj3KnJ+fn48TJ07grbfe+pcrq7oYFEREpBWvoyAiIq0YFEREpBWDgoiItGJQEBGRVgwKIh1KT0/HhAkT0KBBAygUCjg6OqJ3795ISEj4V+uQyWTYtWvXv/qeVHXxOgoiHfnrr7/g6ekJa2trLFmyBC1btkRRURFiY2MRHByMP//8U98lElUIT48l0hFfX1+cOXMGFy5cgIWFhdq8nJwcWFtb48aNG5gwYQISEhJgZGSEHj16IDIyUrySfdiwYcjJyVHbG5g8eTJSUlJw4MABAECXLl3QqlUrmJqa4osvvoBcLsfYsWMxZ84cAED9+vVx/fp18fVOTk7466+/KnPVqYrj0BORDmRlZSEmJgbBwcEaIQEA1tbWUKlU6NOnD7KysnDw4EHEx8fj6tWrGDRokOT327JlCywsLHDs2DFERERg3rx5iI+PB/Dklu8AsGnTJty+fVucJqooDj0R6cDly5chCMJzb4oIAAkJCTh79iyuXbsGR0dHAMBXX32F5s2b4/jx42jXrl25369Vq1aYPXs2AKBx48ZYs2YNEhIS0L17d/EBUdbW1rC3t3+JtSJ6gnsURDpQnhHctLQ0ODo6iiEBAC4uLrC2tkZaWpqk92vVqpXadJ06dZCZmSlpGUTlxaAg0oHGjRtDJpO99AFrIyMjjdApKirS6Pfs/bNkMhlUKtVLvTfR8zAoiHSgRo0a8PHxQVRUFPLz8zXm5+TkoFmzZrh58yZu3rwptp8/fx45OTlwcXEBANSuXRu3b99We21KSorkekxMTPiEN9IZBgWRjkRFRaGkpARvvPEGfvjhB1y6dAlpaWlYvXo1PDw84OXlhZYtWyIgIAAnT55EUlIShg4dirfeegvu7u4AgK5du+LEiRP46quvcOnSJcyePRupqamSa6lfvz4SEhKQnp6O7OxsXa8qvWIYFEQ60qBBA5w8eRJvv/02PvzwQ7Ro0QLdu3dHQkIC1q1bB5lMhp9//hk2Njbo3LkzvLy80KBBA+zYsUNcho+PD2bOnImpU6eiXbt2uH//PoYOHSq5lmXLliE+Ph6Ojo58BC29NF5HQUREWnGPgoiItGJQEBGRVgwKIiLSikFBRERaMSiIiEgrBgUREWnFoCAiIq0YFEREpBWDgoiItGJQEBGRVgwKIiLSikFBRERa/T/sQOjhKE3hxQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_frequency = data['Exited'].value_counts()\n",
    "class_frequency.plot(kind='bar', title='Bank Customer Exits', xlabel='Count' , ylabel='Number of Customers', figsize=[4, 3], grid=True)\n",
    "class_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 10,000 customers, 2037 of them have left the bank. Just slightly above 20% of Beta Banks customers are recorded as exited the bank. The ratio of those who have not left the bank to those who have is 11-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot encoding is performed on the dataset and placed in the data_ohe variable\n",
    "# drop_first=True parameter is used to avoid the dummy trap\n",
    "data_ohe = pd.get_dummies(data, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId  CreditScore  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          1    15634602          619   42     2.0       0.00              1   \n",
       "1          2    15647311          608   41     1.0   83807.86              1   \n",
       "2          3    15619304          502   42     8.0  159660.80              3   \n",
       "3          4    15701354          699   39     1.0       0.00              2   \n",
       "4          5    15737888          850   43     2.0  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0          1               1        101348.88       1                  0   \n",
       "1          0               1        112542.58       0                  0   \n",
       "2          1               0        113931.57       1                  0   \n",
       "3          0               0         93826.63       0                  0   \n",
       "4          1               1         79084.10       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare the target as the 'Exited' column and everything else as features\n",
    "target = data_ohe['Exited']\n",
    "features = data_ohe.drop('Exited', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataset needs to be split into three different set, one for training(60%),\n",
    "# one for validation, and one for final testing(both 20%)\n",
    "# the first split gives us a training set of 60% and 'other' set of 40% to later be split\n",
    "features_train, features_other, target_train, target_other = train_test_split(features, target, test_size=0.4, random_state=12345)\n",
    "\n",
    "# here the 'other' dataset, of 40% the original, is split in half to get is 20% for 'valid'  set, and 20% for 'test' set\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_other, target_other, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 13)\n",
      "(2000, 13)\n",
      "(2000, 13)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize so all features are considered equal\n",
    "pd.options.mode.chained_assignment = None\n",
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative values are those of which the 'Exited' target feature is equal to 0 which means the customer has not left. A value of 1 means the customer has left. To find find the imbalance of the datasets, the percentage of each target value is found. All of the sets are very similar sitting around 80% for each negative target value, and around 20% for each positive target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "Negative class : 80.07%\n",
      "Positive class : 19.93%\n",
      "\n",
      "Validation Set\n",
      "Negative class : 79.1%\n",
      "Positive class : 20.9%\n",
      "\n",
      "Test Set\n",
      "Negative class : 78.85%\n",
      "Positive class : 21.15%\n"
     ]
    }
   ],
   "source": [
    "print('Training Set')\n",
    "print(f'Negative class : {round(target_train[target_train == 0].count() * 100 / len(target_train), 2)}%') \n",
    "print(f'Positive class : {round(target_train[target_train == 1].count() * 100 / len(target_train), 2)}%\\n') \n",
    "\n",
    "print('Validation Set')\n",
    "print(f'Negative class : {(target_valid[target_valid == 0].count() * 100 / len(target_valid))}%') \n",
    "print(f'Positive class : {(target_valid[target_valid == 1].count() * 100 / len(target_valid))}%\\n') \n",
    "\n",
    "print('Test Set')\n",
    "print(f'Negative class : {(target_test[target_test == 0].count() * 100 / len(target_test))}%') \n",
    "print(f'Positive class : {(target_test[target_test == 1].count() * 100 / len(target_test))}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:\n",
      "0.0\n",
      "AUC-ROC:\n",
      "0.49305282514411536\n"
     ]
    }
   ],
   "source": [
    "# Train the regression model prior to fixing imbalance\n",
    "model = LogisticRegression(random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1 Score:')\n",
    "print(f1_score(target_valid, predicted_valid))\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print('AUC-ROC:')\n",
    "print(roc_auc_score(target_valid, probabilities_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f1 score on the logistic regression modek is very low while the AUC-ROC metric is almost at 0.5 which is pretty average. Next we will see if balancing out the class weight and downsampling will result in better values for both scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:\n",
      "0.3457402812241522\n",
      "AUC-ROC:\n",
      "0.5068624900949074\n"
     ]
    }
   ],
   "source": [
    "# Downsample and balance class weight\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=12345)]+ [features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=12345)]+ [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=12345)\n",
    "    return features_downsampled, target_downsampled\n",
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.1)\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', random_state=12345)\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1 Score:')\n",
    "print(f1_score(target_valid, predicted_valid))\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print('AUC-ROC:')\n",
    "print(roc_auc_score(target_valid, probabilities_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Down sampling did increase the f1 score to 0.35 and brought the AUC-ROC score up a bit to 0.51. Although both scores increased the f1 score isn't at the required score of 0.59. We will see if upsampling, while still balancing the class weight will increase the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:\n",
      "0.0\n",
      "AUC-ROC:\n",
      "0.4930694596507359\n"
     ]
    }
   ],
   "source": [
    "# see if upsampling the mode will give better results\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    return features_upsampled, target_upsampled\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 10)\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', random_state=12345)\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1 Score:')\n",
    "print(f1_score(target_valid, predicted_valid))\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print('AUC-ROC:')\n",
    "print(roc_auc_score(target_valid, probabilities_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampling resulted in a similar result to our original logistic regression model. Lets try out other models to meet the requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:\n",
      "0.5179856115107915\n",
      "AUC-ROC:\n",
      "0.6951620805835991\n"
     ]
    }
   ],
   "source": [
    "# Train the decision tree model prior to making impovements\n",
    "model = DecisionTreeClassifier(random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1 Score:')\n",
    "print(f1_score(target_valid, predicted_valid))\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print('AUC-ROC:')\n",
    "print(roc_auc_score(target_valid, probabilities_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree model is much better even without any improvements to it. It's f1 score is 0.52, still just short of the requirement, but its AUC-ROC score is 0.70, higher than the average. Next we'll make some changes to this model to see if it can improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: DecisionTreeClassifier(max_depth=7, random_state=12345)\n",
      "Best F1 Score: 0.5175370226032736\n",
      "AUC-ROC Score: 0.8048727006575167\n",
      "Best Depth: 7\n"
     ]
    }
   ],
   "source": [
    "# find best depth and upsample the decision tree model\n",
    "best_model2 = None\n",
    "best_result2 = 0\n",
    "best_depth2 = 0\n",
    "\n",
    "for depth in range(1, 10):\n",
    "    model2 = DecisionTreeClassifier(random_state=12345, max_depth=depth) \n",
    "    model2.fit(features_upsampled, target_upsampled) \n",
    "    predictions_valid2 = model2.predict(features_valid) \n",
    "    f1 = f1_score(target_valid, predictions_valid2)\n",
    "    \n",
    "    if f1 > best_result2:\n",
    "        best_model2 = model2\n",
    "        best_result2 = f1\n",
    "        best_depth2 = depth\n",
    "        \n",
    "probabilities_valid = best_model2.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print('Best Model:', best_model2)\n",
    "print('Best F1 Score:', best_result2)\n",
    "print('AUC-ROC Score:', auc_roc)\n",
    "print('Best Depth:', best_depth2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampling and finding the best depth for the decision tree hardly changed the f1 score, but the AUC-ROC score improved to 0.80. After looping through different depths, it was found that a depth of 7 was the best for this model. Lets see if downsampling, while still finding the best depth will improve the results of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: DecisionTreeClassifier(max_depth=8, random_state=12345)\n",
      "Best F1 Score: 0.49241877256317684\n",
      "AUC-ROC Score: 0.7491077855539896\n",
      "Best Depth: 8\n"
     ]
    }
   ],
   "source": [
    "# find best depth and downsample to see if there are better results\n",
    "best_model2 = None\n",
    "best_result2 = 0\n",
    "best_depth2 = 0\n",
    "\n",
    "for depth in range(1, 10):\n",
    "    model2 = DecisionTreeClassifier(random_state=12345, max_depth=depth) \n",
    "    model2.fit(features_downsampled, target_downsampled) \n",
    "    predictions_valid2 = model2.predict(features_valid) \n",
    "    f1 = f1_score(target_valid, predictions_valid2)\n",
    "    \n",
    "    if f1 > best_result2:\n",
    "        best_model2 = model2\n",
    "        best_result2 = f1\n",
    "        best_depth2 = depth\n",
    "        \n",
    "probabilities_valid = best_model2.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print('Best Model:', best_model2)\n",
    "print('Best F1 Score:', best_result2)\n",
    "print('AUC-ROC Score:', auc_roc)\n",
    "print('Best Depth:', best_depth2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsampling gave us worse results for the f1 score at 0.49. Although the AUC-ROC score is lower as well, it is still a good score at 0.75. The best depth was 8 for the downsampled version of the decision tree model. Next, lets see if te random forest model will help us reach the required f1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:\n",
      "0.5598755832037325\n",
      "AUC-ROC:\n",
      "0.8393840090975629\n"
     ]
    }
   ],
   "source": [
    "# Train the random forest model prior to making impovements\n",
    "model = RandomForestClassifier(random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1 Score:')\n",
    "print(f1_score(target_valid, predicted_valid))\n",
    "\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "print('AUC-ROC:')\n",
    "print(roc_auc_score(target_valid, probabilities_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model without any improvements gave us the best results of 0.56 for the f1 score, and 0.84 for the AUC-ROC score. Lets first try downsampling, finding the best depth, and finding the best estimators to get a higher f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: RandomForestClassifier(max_depth=15, n_estimators=4, random_state=12345)\n",
      "Best F1 Score: 0.48801742919389973\n",
      "AUC-ROC Score: 0.7578257792510237\n",
      "Best Depth: 15\n",
      "Best n_estimators: 4\n"
     ]
    }
   ],
   "source": [
    "# Downsample, find best depth, and best estimators for random forest model\n",
    "best_model3 = None\n",
    "best_result3 = 0\n",
    "best_depth3 = 0\n",
    "best_est = 0\n",
    "\n",
    "for est in range(1, 50):\n",
    "     for depth in range (1, 50):\n",
    "        model3 = RandomForestClassifier(max_depth=depth, random_state=12345, n_estimators=est)\n",
    "        model3.fit(features_downsampled, target_downsampled)\n",
    "        predictions_valid3 = model3.predict(features_valid)\n",
    "        f1 = f1_score(target_valid, predictions_valid3)\n",
    "        \n",
    "        if f1 > best_result3:\n",
    "            best_model3 = model3\n",
    "            best_result3 = f1\n",
    "            best_depth3 = depth\n",
    "            best_est = est\n",
    "\n",
    "probabilities_valid = best_model3.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print('Best Model:', best_model3)\n",
    "print('Best F1 Score:', best_result3)\n",
    "print('AUC-ROC Score:', auc_roc)\n",
    "print('Best Depth:', best_depth3)\n",
    "print('Best n_estimators:', best_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was looped with different estimators and depths to get a best depth of 15, and best number of estimators of 4. These parmeters gave us an f1 score of 0.49 and a ROC-AUC score of 0.76. These results are worse than the original random forest model, so we will try upsampling instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: RandomForestClassifier(max_depth=17, n_estimators=21, random_state=12345)\n",
      "Best F1 Score: 0.6057571964956197\n",
      "AUC-ROC Score: 0.8325222751165926\n",
      "Best Depth: 17\n",
      "Best n_estimators: 21\n"
     ]
    }
   ],
   "source": [
    "# Upsample, find best depth, and best estimators for better result on random forest model\n",
    "best_model3 = None\n",
    "best_result3 = 0\n",
    "best_depth3 = 0\n",
    "best_est = 0\n",
    "\n",
    "for est in range(1, 50):\n",
    "     for depth in range (1, 50):\n",
    "        model3 = RandomForestClassifier(max_depth=depth, random_state=12345, n_estimators=est)\n",
    "        model3.fit(features_upsampled, target_upsampled)\n",
    "        predictions_valid3 = model3.predict(features_valid)\n",
    "        f1 = f1_score(target_valid, predictions_valid3)\n",
    "        \n",
    "        if f1 > best_result3:\n",
    "            best_model3 = model3\n",
    "            best_result3 = f1\n",
    "            best_depth3 = depth\n",
    "            best_est = est\n",
    "\n",
    "probabilities_valid = best_model3.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "print('Best Model:', best_model3)\n",
    "print('Best F1 Score:', best_result3)\n",
    "print('AUC-ROC Score:', auc_roc)\n",
    "print('Best Depth:', best_depth3)\n",
    "print('Best n_estimators:', best_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally when we upsample the random forest we get above the required f1 score at 0.61. The AUC-ROC score was also good at 0.83. The upssampled model found that 17 was our best depth, while 21 was the best number of estimators. We'll put this into our test set and see the results to predict the number of customers leaving the bank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.561314791403287\n",
      "AUC-ROC Score: 0.8282056932470456\n"
     ]
    }
   ],
   "source": [
    "model3 = RandomForestClassifier(max_depth=17, random_state=12345, n_estimators=21)\n",
    "model3.fit(features_upsampled, target_upsampled)\n",
    "predictions_test = model3.predict(features_test)\n",
    "f1 = f1_score(target_test, predictions_test)\n",
    "        \n",
    "probabilities_test = model3.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "\n",
    "print('F1 Score:', f1)\n",
    "print('AUC-ROC Score:', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After putting the best parameters for the random forest model, the f1 score came t be 0.56 while the AUC-ROC score is 0.83. The predictions will then be used to calculate how many are actually projected to leave the bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for prediction in predictions_test:\n",
    "    if prediction == 1:\n",
    "        total += 1\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According the the model 368 people will leave the bank out of the 2000 in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for the customers at Beta Bank was first preprocessed. The data was familiarized, missing values were filled, and certain columns were removed that didn't affect the computer model process. One-hot encoding was performed, while also avoiding the dummy trap. The data was split into a training set, validation set, and test set approprietly. The data was then standardize so no feature to precedent over another.\n",
    "\n",
    "Three different models were then made; a logistic regression model, a decision tree model, and a random forest model. Each model was first trained without taking into account the imbalance. After each model was modified, the random forest model was found to be the best, passing the required f1 score of 0.59; while also having a AUC-ROC score of 0.83. The parameterx it used to get these results were a number of estimators at 21, and a depth of 17, while also using an upscaled dataset. These parameters were used in the final test set.\n",
    "\n",
    "After using the parameters just mention in the test set, the models f1 score and AUC-ROC score were very close compared to what they just were for the validation set. The model predicted that of the 2000 people using beta bank in the test set, 368 of them would leave the bank. "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 814,
    "start_time": "2025-01-07T16:06:03.725Z"
   },
   {
    "duration": 26,
    "start_time": "2025-01-07T16:06:38.733Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-07T16:07:03.983Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-07T16:08:07.381Z"
   },
   {
    "duration": 219,
    "start_time": "2025-01-07T16:15:52.875Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-07T16:15:58.796Z"
   },
   {
    "duration": 52,
    "start_time": "2025-01-07T16:21:20.089Z"
   },
   {
    "duration": 51,
    "start_time": "2025-01-07T16:22:32.763Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-07T16:23:09.615Z"
   },
   {
    "duration": 654,
    "start_time": "2025-01-07T16:27:06.925Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-07T16:27:58.413Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-07T16:28:09.188Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-07T16:28:10.808Z"
   },
   {
    "duration": 12,
    "start_time": "2025-01-07T16:28:12.490Z"
   },
   {
    "duration": 35,
    "start_time": "2025-01-07T16:30:14.873Z"
   },
   {
    "duration": 749,
    "start_time": "2025-01-07T16:30:34.798Z"
   },
   {
    "duration": 18,
    "start_time": "2025-01-07T16:30:35.549Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-07T16:30:35.568Z"
   },
   {
    "duration": 23,
    "start_time": "2025-01-07T16:30:35.583Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-07T16:30:35.607Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-07T16:30:35.612Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-07T16:30:35.617Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-07T16:30:35.629Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-07T16:47:15.687Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-07T16:50:04.577Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-07T16:52:48.835Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-07T17:23:27.855Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-07T17:23:54.225Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-07T17:26:08.202Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-07T17:34:20.796Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-07T17:34:37.577Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-07T17:34:47.530Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-07T17:35:52.988Z"
   },
   {
    "duration": 218,
    "start_time": "2025-01-07T17:44:56.608Z"
   },
   {
    "duration": 752,
    "start_time": "2025-01-07T17:45:20.775Z"
   },
   {
    "duration": 17,
    "start_time": "2025-01-07T17:45:21.529Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-07T17:45:21.548Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-07T17:45:21.564Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-07T17:45:21.576Z"
   },
   {
    "duration": 25,
    "start_time": "2025-01-07T17:45:21.581Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-07T17:45:21.607Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-07T17:45:21.616Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-07T17:45:21.628Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-07T17:45:21.635Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-07T17:45:21.642Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-07T17:45:21.659Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-07T17:46:37.499Z"
   },
   {
    "duration": 18,
    "start_time": "2025-01-07T17:47:18.660Z"
   },
   {
    "duration": 17,
    "start_time": "2025-01-07T17:47:40.570Z"
   },
   {
    "duration": 18,
    "start_time": "2025-01-07T17:48:09.827Z"
   },
   {
    "duration": 162,
    "start_time": "2025-01-08T00:29:12.991Z"
   },
   {
    "duration": 783,
    "start_time": "2025-01-08T00:29:17.724Z"
   },
   {
    "duration": 31,
    "start_time": "2025-01-08T00:29:18.509Z"
   },
   {
    "duration": 18,
    "start_time": "2025-01-08T00:29:18.543Z"
   },
   {
    "duration": 12,
    "start_time": "2025-01-08T00:29:18.564Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-08T00:29:18.577Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-08T00:29:18.583Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-08T00:29:18.588Z"
   },
   {
    "duration": 39,
    "start_time": "2025-01-08T00:29:18.599Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-08T00:29:18.640Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-08T00:29:18.647Z"
   },
   {
    "duration": 23,
    "start_time": "2025-01-08T00:29:18.655Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-08T00:29:20.623Z"
   },
   {
    "duration": 19,
    "start_time": "2025-01-08T00:36:07.868Z"
   },
   {
    "duration": 24,
    "start_time": "2025-01-08T00:36:45.522Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-08T00:37:09.120Z"
   },
   {
    "duration": 20,
    "start_time": "2025-01-08T00:37:41.326Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-08T00:37:59.490Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-08T00:38:48.516Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-08T00:41:09.812Z"
   },
   {
    "duration": 804,
    "start_time": "2025-01-08T21:43:46.260Z"
   },
   {
    "duration": 29,
    "start_time": "2025-01-08T21:43:47.066Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-08T21:43:47.097Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-08T21:43:47.112Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-08T21:43:47.124Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-08T21:43:47.129Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-08T21:43:47.136Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-08T21:43:47.146Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-08T21:43:47.156Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-08T21:43:47.162Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-08T21:43:47.170Z"
   },
   {
    "duration": 39,
    "start_time": "2025-01-08T21:43:47.188Z"
   },
   {
    "duration": 290,
    "start_time": "2025-01-08T21:45:32.925Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-08T21:46:01.915Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-08T21:47:48.930Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-08T21:47:59.751Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-08T21:48:34.286Z"
   },
   {
    "duration": 782,
    "start_time": "2025-01-08T21:48:42.047Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-08T21:48:42.831Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-08T21:48:42.848Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-08T21:48:42.863Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-08T21:48:42.874Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-08T21:48:42.879Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-08T21:48:42.884Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-08T21:48:42.923Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-08T21:48:42.934Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-08T21:48:42.941Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-08T21:48:42.950Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-08T21:48:42.966Z"
   },
   {
    "duration": 51,
    "start_time": "2025-01-08T21:48:42.974Z"
   },
   {
    "duration": 18,
    "start_time": "2025-01-08T21:49:32.823Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-08T21:49:36.496Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-08T21:51:00.245Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-08T21:51:02.449Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-08T21:51:03.594Z"
   },
   {
    "duration": 44,
    "start_time": "2025-01-08T21:53:34.996Z"
   },
   {
    "duration": 18,
    "start_time": "2025-01-08T21:54:09.306Z"
   },
   {
    "duration": 21,
    "start_time": "2025-01-08T21:56:32.503Z"
   },
   {
    "duration": 47,
    "start_time": "2025-01-08T22:02:32.354Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-08T22:03:45.403Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-08T22:03:45.414Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-08T22:03:45.432Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-08T22:03:45.444Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-08T22:03:45.455Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-08T22:03:45.460Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-08T22:03:45.464Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-08T22:03:45.473Z"
   },
   {
    "duration": 41,
    "start_time": "2025-01-08T22:03:45.484Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-08T22:03:45.528Z"
   },
   {
    "duration": 17,
    "start_time": "2025-01-08T22:03:45.537Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-08T22:03:45.557Z"
   },
   {
    "duration": 65,
    "start_time": "2025-01-08T22:03:45.566Z"
   },
   {
    "duration": 122,
    "start_time": "2025-01-08T22:03:45.633Z"
   },
   {
    "duration": 779,
    "start_time": "2025-01-08T22:03:51.339Z"
   },
   {
    "duration": 24,
    "start_time": "2025-01-08T22:08:47.000Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-08T22:12:32.940Z"
   },
   {
    "duration": 231,
    "start_time": "2025-01-08T22:22:46.055Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-08T22:23:31.874Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-08T22:23:31.879Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-08T22:23:31.897Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-08T22:23:31.908Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-08T22:23:31.919Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-08T22:23:31.923Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-08T22:23:31.928Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-08T22:23:31.937Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-08T22:23:31.948Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-08T22:23:31.954Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-08T22:23:31.961Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-08T22:23:31.978Z"
   },
   {
    "duration": 55,
    "start_time": "2025-01-08T22:23:31.986Z"
   },
   {
    "duration": 32,
    "start_time": "2025-01-08T22:23:38.629Z"
   },
   {
    "duration": 23,
    "start_time": "2025-01-08T22:45:57.863Z"
   },
   {
    "duration": 31,
    "start_time": "2025-01-08T22:46:05.662Z"
   },
   {
    "duration": 34,
    "start_time": "2025-01-08T23:10:41.153Z"
   },
   {
    "duration": 302,
    "start_time": "2025-01-08T23:11:15.893Z"
   },
   {
    "duration": 73,
    "start_time": "2025-01-08T23:15:22.717Z"
   },
   {
    "duration": 302,
    "start_time": "2025-01-08T23:18:06.599Z"
   },
   {
    "duration": 307,
    "start_time": "2025-01-08T23:19:32.413Z"
   },
   {
    "duration": 81,
    "start_time": "2025-01-08T23:20:27.489Z"
   },
   {
    "duration": 28,
    "start_time": "2025-01-08T23:22:02.925Z"
   },
   {
    "duration": 19,
    "start_time": "2025-01-08T23:22:05.266Z"
   },
   {
    "duration": 46,
    "start_time": "2025-01-08T23:23:11.470Z"
   },
   {
    "duration": 769,
    "start_time": "2025-01-08T23:25:27.506Z"
   },
   {
    "duration": 135894,
    "start_time": "2025-01-08T23:46:53.282Z"
   },
   {
    "duration": 745306,
    "start_time": "2025-01-08T23:50:57.580Z"
   },
   {
    "duration": 157,
    "start_time": "2025-01-09T11:27:52.371Z"
   },
   {
    "duration": 856,
    "start_time": "2025-01-09T11:27:56.620Z"
   },
   {
    "duration": 25,
    "start_time": "2025-01-09T11:27:57.478Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-09T11:27:57.504Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-09T11:27:57.522Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-09T11:27:57.535Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-09T11:27:57.540Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-09T11:27:57.545Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-09T11:27:57.555Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-09T11:27:57.567Z"
   },
   {
    "duration": 42,
    "start_time": "2025-01-09T11:27:57.573Z"
   },
   {
    "duration": 18,
    "start_time": "2025-01-09T11:27:57.616Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-09T11:27:57.635Z"
   },
   {
    "duration": 79,
    "start_time": "2025-01-09T11:27:57.643Z"
   },
   {
    "duration": 98,
    "start_time": "2025-01-09T11:27:57.726Z"
   },
   {
    "duration": 118,
    "start_time": "2025-01-09T11:27:57.826Z"
   },
   {
    "duration": 123,
    "start_time": "2025-01-09T11:27:58.010Z"
   },
   {
    "duration": 312,
    "start_time": "2025-01-09T11:27:58.134Z"
   },
   {
    "duration": 80,
    "start_time": "2025-01-09T11:27:58.448Z"
   },
   {
    "duration": 747,
    "start_time": "2025-01-09T11:27:58.529Z"
   },
   {
    "duration": 132631,
    "start_time": "2025-01-09T11:27:59.278Z"
   },
   {
    "duration": 732675,
    "start_time": "2025-01-09T11:30:11.911Z"
   },
   {
    "duration": 306,
    "start_time": "2025-01-09T11:42:56.555Z"
   },
   {
    "duration": 279,
    "start_time": "2025-01-09T11:45:06.101Z"
   },
   {
    "duration": 304,
    "start_time": "2025-01-09T11:45:15.018Z"
   },
   {
    "duration": 300,
    "start_time": "2025-01-09T11:45:22.205Z"
   },
   {
    "duration": 299,
    "start_time": "2025-01-09T11:45:29.162Z"
   },
   {
    "duration": 362,
    "start_time": "2025-01-09T11:45:36.852Z"
   },
   {
    "duration": 314,
    "start_time": "2025-01-09T11:46:14.631Z"
   },
   {
    "duration": 293,
    "start_time": "2025-01-09T11:46:55.176Z"
   },
   {
    "duration": 305,
    "start_time": "2025-01-09T11:47:02.465Z"
   },
   {
    "duration": 299,
    "start_time": "2025-01-09T11:47:22.005Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-09T11:48:23.238Z"
   },
   {
    "duration": 144,
    "start_time": "2025-01-09T12:05:59.701Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-09T12:06:06.127Z"
   },
   {
    "duration": 293,
    "start_time": "2025-01-09T12:06:22.879Z"
   },
   {
    "duration": 77613,
    "start_time": "2025-01-09T12:19:25.355Z"
   },
   {
    "duration": 292,
    "start_time": "2025-01-09T12:22:32.254Z"
   },
   {
    "duration": 60,
    "start_time": "2025-01-09T12:22:45.716Z"
   },
   {
    "duration": 21,
    "start_time": "2025-01-09T12:28:33.517Z"
   },
   {
    "duration": 30,
    "start_time": "2025-01-09T12:31:40.512Z"
   },
   {
    "duration": 43,
    "start_time": "2025-01-09T12:35:01.134Z"
   },
   {
    "duration": 44,
    "start_time": "2025-01-09T12:35:07.911Z"
   },
   {
    "duration": 44,
    "start_time": "2025-01-09T12:35:12.919Z"
   },
   {
    "duration": 175,
    "start_time": "2025-01-09T12:35:24.599Z"
   },
   {
    "duration": 154,
    "start_time": "2025-01-09T12:35:32.181Z"
   },
   {
    "duration": 124,
    "start_time": "2025-01-09T12:35:36.897Z"
   },
   {
    "duration": 82,
    "start_time": "2025-01-09T12:35:42.239Z"
   },
   {
    "duration": 267,
    "start_time": "2025-01-09T12:35:58.643Z"
   },
   {
    "duration": 67,
    "start_time": "2025-01-09T12:36:20.740Z"
   },
   {
    "duration": 81,
    "start_time": "2025-01-09T12:36:28.824Z"
   },
   {
    "duration": 118,
    "start_time": "2025-01-09T12:36:33.874Z"
   },
   {
    "duration": 82,
    "start_time": "2025-01-09T12:36:42.146Z"
   },
   {
    "duration": 69,
    "start_time": "2025-01-09T12:36:48.741Z"
   },
   {
    "duration": 88,
    "start_time": "2025-01-09T12:36:56.008Z"
   },
   {
    "duration": 45,
    "start_time": "2025-01-09T12:37:02.324Z"
   },
   {
    "duration": 37,
    "start_time": "2025-01-09T12:37:09.507Z"
   },
   {
    "duration": 70,
    "start_time": "2025-01-09T12:37:16.954Z"
   },
   {
    "duration": 48,
    "start_time": "2025-01-09T12:37:24.361Z"
   },
   {
    "duration": 729,
    "start_time": "2025-01-09T12:38:59.770Z"
   },
   {
    "duration": 754,
    "start_time": "2025-01-09T12:39:43.795Z"
   },
   {
    "duration": 17,
    "start_time": "2025-01-09T12:39:44.551Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-09T12:39:44.569Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-09T12:39:44.585Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-09T12:39:44.608Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-09T12:39:44.614Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-09T12:39:44.618Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-09T12:39:44.628Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-09T12:39:44.638Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-09T12:39:44.645Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-09T12:39:44.653Z"
   },
   {
    "duration": 43,
    "start_time": "2025-01-09T12:39:44.671Z"
   },
   {
    "duration": 19,
    "start_time": "2025-01-09T12:39:44.715Z"
   },
   {
    "duration": 88,
    "start_time": "2025-01-09T12:39:44.737Z"
   },
   {
    "duration": 192,
    "start_time": "2025-01-09T12:39:44.827Z"
   },
   {
    "duration": 108,
    "start_time": "2025-01-09T12:39:45.024Z"
   },
   {
    "duration": 250,
    "start_time": "2025-01-09T12:39:45.134Z"
   },
   {
    "duration": 68,
    "start_time": "2025-01-09T12:39:45.386Z"
   },
   {
    "duration": 607,
    "start_time": "2025-01-09T12:39:49.282Z"
   },
   {
    "duration": 45,
    "start_time": "2025-01-09T12:39:55.670Z"
   },
   {
    "duration": 249,
    "start_time": "2025-01-09T12:40:12.525Z"
   },
   {
    "duration": 782,
    "start_time": "2025-01-09T12:40:45.749Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-09T12:40:46.533Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-09T12:40:46.550Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-09T12:40:46.567Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-09T12:40:46.579Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-09T12:40:46.584Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-09T12:40:46.609Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-09T12:40:46.618Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-09T12:40:46.628Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-09T12:40:46.634Z"
   },
   {
    "duration": 17,
    "start_time": "2025-01-09T12:40:46.644Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-09T12:40:46.662Z"
   },
   {
    "duration": 53,
    "start_time": "2025-01-09T12:40:46.670Z"
   },
   {
    "duration": 100,
    "start_time": "2025-01-09T12:40:46.727Z"
   },
   {
    "duration": 192,
    "start_time": "2025-01-09T12:40:46.831Z"
   },
   {
    "duration": 111,
    "start_time": "2025-01-09T12:40:47.028Z"
   },
   {
    "duration": 284,
    "start_time": "2025-01-09T12:40:47.141Z"
   },
   {
    "duration": 60,
    "start_time": "2025-01-09T12:40:47.426Z"
   },
   {
    "duration": 636,
    "start_time": "2025-01-09T12:40:47.488Z"
   },
   {
    "duration": 121152,
    "start_time": "2025-01-09T12:40:56.479Z"
   },
   {
    "duration": 614995,
    "start_time": "2025-01-09T12:43:27.746Z"
   },
   {
    "duration": 226,
    "start_time": "2025-01-09T12:54:09.248Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-09T12:58:36.477Z"
   },
   {
    "duration": 815,
    "start_time": "2025-01-09T12:59:30.540Z"
   },
   {
    "duration": 20,
    "start_time": "2025-01-09T12:59:31.359Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-09T12:59:31.381Z"
   },
   {
    "duration": 18,
    "start_time": "2025-01-09T12:59:31.396Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-09T12:59:31.416Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-09T12:59:34.764Z"
   },
   {
    "duration": 755,
    "start_time": "2025-01-09T12:59:43.771Z"
   },
   {
    "duration": 17,
    "start_time": "2025-01-09T12:59:44.528Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-09T12:59:44.547Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-09T12:59:44.562Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-09T12:59:44.574Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-09T12:59:44.579Z"
   },
   {
    "duration": 32,
    "start_time": "2025-01-09T12:59:44.584Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-09T12:59:44.618Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-09T12:59:44.628Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-09T12:59:44.637Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-09T12:59:44.646Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-09T12:59:44.662Z"
   },
   {
    "duration": 54,
    "start_time": "2025-01-09T12:59:44.670Z"
   },
   {
    "duration": 95,
    "start_time": "2025-01-09T12:59:44.729Z"
   },
   {
    "duration": 185,
    "start_time": "2025-01-09T12:59:44.826Z"
   },
   {
    "duration": 117,
    "start_time": "2025-01-09T12:59:45.016Z"
   },
   {
    "duration": 305,
    "start_time": "2025-01-09T12:59:45.134Z"
   },
   {
    "duration": 80,
    "start_time": "2025-01-09T12:59:45.441Z"
   },
   {
    "duration": 759,
    "start_time": "2025-01-09T12:59:45.523Z"
   },
   {
    "duration": 133362,
    "start_time": "2025-01-09T12:59:46.284Z"
   },
   {
    "duration": 739445,
    "start_time": "2025-01-09T13:01:59.648Z"
   },
   {
    "duration": 279,
    "start_time": "2025-01-09T13:14:19.095Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-09T13:14:19.376Z"
   },
   {
    "duration": 294,
    "start_time": "2025-01-09T13:14:49.066Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-09T13:14:57.842Z"
   },
   {
    "duration": 165,
    "start_time": "2025-01-09T13:16:00.022Z"
   },
   {
    "duration": 78,
    "start_time": "2025-01-09T13:16:17.746Z"
   },
   {
    "duration": 78,
    "start_time": "2025-01-09T13:30:28.957Z"
   },
   {
    "duration": 66,
    "start_time": "2025-01-09T13:30:33.237Z"
   },
   {
    "duration": 101,
    "start_time": "2025-01-09T13:30:37.252Z"
   },
   {
    "duration": 293,
    "start_time": "2025-01-09T13:30:46.577Z"
   },
   {
    "duration": 285,
    "start_time": "2025-01-09T13:43:03.989Z"
   },
   {
    "duration": 199,
    "start_time": "2025-01-09T13:43:30.541Z"
   },
   {
    "duration": 85,
    "start_time": "2025-01-09T13:43:39.925Z"
   },
   {
    "duration": 297,
    "start_time": "2025-01-09T13:43:58.645Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-09T13:44:52.601Z"
   },
   {
    "duration": 5,
    "start_time": "2025-01-09T13:46:24.232Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-09T13:46:29.666Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-09T13:49:53.987Z"
   },
   {
    "duration": 833,
    "start_time": "2025-01-10T12:11:46.651Z"
   },
   {
    "duration": 23,
    "start_time": "2025-01-10T12:11:47.486Z"
   },
   {
    "duration": 14,
    "start_time": "2025-01-10T12:11:47.512Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-10T12:11:47.529Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-10T12:11:47.540Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-10T12:11:47.546Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-10T12:11:47.550Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-10T12:11:47.560Z"
   },
   {
    "duration": 38,
    "start_time": "2025-01-10T12:11:47.571Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-10T12:11:47.612Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-10T12:11:47.623Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-10T12:11:47.627Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-10T12:11:47.645Z"
   },
   {
    "duration": 68,
    "start_time": "2025-01-10T12:11:47.653Z"
   },
   {
    "duration": 111,
    "start_time": "2025-01-10T12:11:47.723Z"
   },
   {
    "duration": 180,
    "start_time": "2025-01-10T12:11:47.836Z"
   },
   {
    "duration": 123,
    "start_time": "2025-01-10T12:11:48.018Z"
   },
   {
    "duration": 331,
    "start_time": "2025-01-10T12:11:48.142Z"
   },
   {
    "duration": 80,
    "start_time": "2025-01-10T12:11:48.474Z"
   },
   {
    "duration": 747,
    "start_time": "2025-01-10T12:11:48.555Z"
   },
   {
    "duration": 132688,
    "start_time": "2025-01-10T12:11:49.309Z"
   },
   {
    "duration": 733899,
    "start_time": "2025-01-10T12:14:01.999Z"
   },
   {
    "duration": 301,
    "start_time": "2025-01-10T12:26:15.900Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-10T12:26:16.203Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-10T13:02:31.842Z"
   },
   {
    "duration": 15,
    "start_time": "2025-01-10T13:02:31.848Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-10T13:02:31.865Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-10T13:02:31.878Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-10T13:02:31.890Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-10T13:02:31.895Z"
   },
   {
    "duration": 10,
    "start_time": "2025-01-10T13:02:31.900Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-10T13:02:31.911Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-10T13:02:31.921Z"
   },
   {
    "duration": 7,
    "start_time": "2025-01-10T13:02:31.927Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-10T13:02:31.935Z"
   },
   {
    "duration": 18,
    "start_time": "2025-01-10T13:02:31.941Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-10T13:02:31.962Z"
   },
   {
    "duration": 55,
    "start_time": "2025-01-10T13:02:31.971Z"
   },
   {
    "duration": 93,
    "start_time": "2025-01-10T13:02:32.028Z"
   },
   {
    "duration": 105,
    "start_time": "2025-01-10T13:02:32.122Z"
   },
   {
    "duration": 184,
    "start_time": "2025-01-10T13:02:32.229Z"
   },
   {
    "duration": 304,
    "start_time": "2025-01-10T13:02:32.415Z"
   },
   {
    "duration": 72,
    "start_time": "2025-01-10T13:02:32.722Z"
   },
   {
    "duration": 753,
    "start_time": "2025-01-10T13:02:32.795Z"
   },
   {
    "duration": 133066,
    "start_time": "2025-01-10T13:02:33.550Z"
   },
   {
    "duration": 733578,
    "start_time": "2025-01-10T13:04:46.618Z"
   },
   {
    "duration": 301,
    "start_time": "2025-01-10T13:17:00.198Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-10T13:17:00.501Z"
   },
   {
    "duration": 161,
    "start_time": "2025-01-10T22:28:25.847Z"
   },
   {
    "duration": 789,
    "start_time": "2025-01-10T22:28:30.779Z"
   },
   {
    "duration": 32,
    "start_time": "2025-01-10T22:28:31.571Z"
   },
   {
    "duration": 16,
    "start_time": "2025-01-10T22:28:31.605Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-10T22:28:31.624Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-10T22:28:31.638Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-10T22:28:31.644Z"
   },
   {
    "duration": 430,
    "start_time": "2025-01-10T22:28:33.683Z"
   },
   {
    "duration": 6,
    "start_time": "2025-01-10T22:28:59.659Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-10T22:29:07.529Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-10T22:30:02.892Z"
   },
   {
    "duration": 22,
    "start_time": "2025-01-10T22:30:02.899Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-10T22:30:02.923Z"
   },
   {
    "duration": 11,
    "start_time": "2025-01-10T22:30:02.937Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-10T22:30:02.950Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-10T22:30:02.956Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-10T22:30:02.962Z"
   },
   {
    "duration": 9,
    "start_time": "2025-01-10T22:30:02.967Z"
   },
   {
    "duration": 12,
    "start_time": "2025-01-10T22:30:02.978Z"
   },
   {
    "duration": 44,
    "start_time": "2025-01-10T22:30:02.991Z"
   },
   {
    "duration": 8,
    "start_time": "2025-01-10T22:30:03.037Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-10T22:30:03.047Z"
   },
   {
    "duration": 25,
    "start_time": "2025-01-10T22:30:03.052Z"
   },
   {
    "duration": 13,
    "start_time": "2025-01-10T22:30:03.080Z"
   },
   {
    "duration": 136,
    "start_time": "2025-01-10T22:30:03.096Z"
   },
   {
    "duration": 108,
    "start_time": "2025-01-10T22:30:03.234Z"
   },
   {
    "duration": 192,
    "start_time": "2025-01-10T22:30:03.344Z"
   },
   {
    "duration": 127,
    "start_time": "2025-01-10T22:30:03.538Z"
   },
   {
    "duration": 332,
    "start_time": "2025-01-10T22:30:03.666Z"
   },
   {
    "duration": 84,
    "start_time": "2025-01-10T22:30:04.000Z"
   },
   {
    "duration": 768,
    "start_time": "2025-01-10T22:30:04.086Z"
   },
   {
    "duration": 138641,
    "start_time": "2025-01-10T22:30:04.857Z"
   },
   {
    "duration": 761338,
    "start_time": "2025-01-10T22:32:23.500Z"
   },
   {
    "duration": 305,
    "start_time": "2025-01-10T22:45:17.284Z"
   },
   {
    "duration": 3,
    "start_time": "2025-01-10T22:46:36.020Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-10T22:48:16.992Z"
   },
   {
    "duration": 17,
    "start_time": "2025-01-10T22:48:39.952Z"
   },
   {
    "duration": 320,
    "start_time": "2025-01-10T22:48:45.708Z"
   },
   {
    "duration": 2131,
    "start_time": "2025-01-10T22:49:00.335Z"
   },
   {
    "duration": 81,
    "start_time": "2025-01-10T22:49:51.474Z"
   },
   {
    "duration": 98,
    "start_time": "2025-01-10T22:50:04.624Z"
   },
   {
    "duration": 4,
    "start_time": "2025-01-10T23:00:35.015Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
